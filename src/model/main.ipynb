{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "from os import wal\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Imports installations etc"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# # !conda install -c pytorch pytorch-cpu torchvision\n",
    "# # !yes Y | conda install -c pytorch pytorch-cpu torchvision\n",
    "# from fastai.data.external import untar_data\n",
    "# !conda install -c pytorch pytorch-cpu torchvision --y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# !conda install -c fastai fastaiorpip install http://download.pytorch.org/whl/cpu/torch-1.0.0-cp36-cp36m-linux_x86_64.whl --y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# !pip install fastai"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# from fastai.vision import *"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# !pip install ffmpeg"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# import fastai # conda install -c pytorch -c fastai fastai=1.0.61"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# conda install -c fastai fastbook\n",
    "# from fastbook import *\n",
    "# fastbook.setup_book()\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.data.external import *\n",
    "from fastai.data.transforms import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.augment import RandomResizedCrop, Resize\n",
    "from fastai.vision.data import ImageDataLoaders, ImageBlock\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Convert videos to images, so we can actually work with them"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/video/train/0-green-blue-9.avi\n"
     ]
    }
   ],
   "source": [
    "# https://medium.com/howtoai/video-classification-with-cnn-rnn-and-pytorch-abe2f9ee031\n",
    "# https://github.com/PacktPublishing/PyTorch-Computer-Vision-Cookbook/blob/master/Chapter10/myutils.py\n",
    "\n",
    "def get_frames(filename, n_frames=1):\n",
    "    print(filename)\n",
    "    frames = []\n",
    "    v_cap = cv2.VideoCapture(filename)\n",
    "    v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_list = np.linspace(0, v_len - 1, n_frames + 1, dtype=np.int16)\n",
    "\n",
    "    for fn in range(v_len):\n",
    "        success, frame = v_cap.read()\n",
    "        if success is False:\n",
    "            continue\n",
    "        if fn in frame_list:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "    v_cap.release()\n",
    "    return frames, v_len\n",
    "\n",
    "\n",
    "def store_frames(frames, path2store):\n",
    "    for ii, frame in enumerate(frames):\n",
    "        plt.imshow(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        # if not os.path.exists(path2store):\n",
    "        #     os.makedirs(path2store)\n",
    "        print(path2store)\n",
    "        path2img = (path2store + \"-frame-\" + str(ii) + \".jpg\").replace(\"\\\\\", \"/\")\n",
    "        # path2img = os.path.join(path2store, \"-frame-\" + str(ii) + \".jpg\").replace(\"\\\\\", \"/\")\n",
    "        print(path2img)\n",
    "        cv2.imwrite(path2img, frame)\n",
    "\n",
    "\n",
    "temp_video_path = \"D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/video/train/0-green-blue-9.avi\"\n",
    "temp_image_path = \"D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/0-green-blue-9\"\n",
    "temp_frames, temp_frame_len = get_frames(temp_video_path, 5)\n",
    "store_frames(temp_frames, temp_image_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "def extract_images_from_directory(video_directory, image_directory, f_num):\n",
    "    _, _, filenames = next(walk(video_directory))\n",
    "    for file in filenames:\n",
    "        full_path = os.path.join(video_directory, file).replace(\"\\\\\", \"/\")\n",
    "        frames, len = get_frames(full_path, f_num)\n",
    "        #cut out the file extension\n",
    "        filename = file.split(\".\")[0]\n",
    "        image_path = os.path.join(image_directory, filename).replace(\"\\\\\", \"/\")\n",
    "        store_frames(frames, image_path)\n",
    "\n",
    "\n",
    "video_train_root = \"D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/video/train/\"\n",
    "video_valid_root = \"D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/video/valid/\"\n",
    "image_train_root = \"D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/\"\n",
    "image_valid_root = \"D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/valid/\"\n",
    "image_root = \"D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image\"\n",
    "\n",
    "frames_per_video = 5\n",
    "\n",
    "# extract_images_from_directory(video_train_root, image_train_root, frames_per_video)\n",
    "# extract_images_from_directory(video_valid_root, image_valid_root, frames_per_video)\n",
    "\n",
    "# for file in valid_filenames:\n",
    "#     full_path = os.path.join(video_valid_root, file).replace(\"\\\\\", \"/\")\n",
    "#     frames, len = get_frames(full_path, frames_per_video)\n",
    "#     #cut out the file extension\n",
    "#     filename = file.split(\".\")[0]\n",
    "#     image_path = os.path.join(image_valid_root, filename).replace(\"\\\\\", \"/\")\n",
    "#     store_frames(frames, image_path)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# file_root = \"../data/seizure_data/images/train/\"\n",
    "# train_image_root = \"D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/\"\n",
    "\n",
    "# store_frames(test_frames, train_image_root)\n",
    "\n",
    "# i = 0\n",
    "# for frame in test_frames :\n",
    "#     plt.imshow(frame)\n",
    "#     # file_root = \"../data/seizure_data/images/train/\"\n",
    "#     file_root = \"D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/images/train/\"\n",
    "#     file_name = \"test-\" + str(i)\n",
    "#     file_extension = \".bmp\"\n",
    "#     filepath = file_root + file_name + file_extension\n",
    "#     # filepath = \"C:/Users/Alina Work/Desktop/temp.bmp\"\n",
    "#     cv2.imwrite(filepath, frame)\n",
    "#     i += i"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Build dataset from frames"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-13-1b126ec7312f>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;31m# https://www.dataspoof.info/post/video-classification-with-fastai-and-deep-learning/\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[1;31m# np.random.seed(42)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m dataset = ImageDataLoaders.from_folder(\n\u001B[0m\u001B[0;32m      4\u001B[0m     \u001B[0mimage_root\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mitem_tfms\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mResize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m224\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\vision\\data.py\u001B[0m in \u001B[0;36mfrom_folder\u001B[1;34m(cls, path, train, valid, valid_pct, seed, vocab, item_tfms, batch_tfms, **kwargs)\u001B[0m\n\u001B[0;32m     92\u001B[0m                            \u001B[0mitem_tfms\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mitem_tfms\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m                            batch_tfms=batch_tfms)\n\u001B[1;32m---> 94\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mcls\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfrom_dblock\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdblock\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     95\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     96\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mclassmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\data\\core.py\u001B[0m in \u001B[0;36mfrom_dblock\u001B[1;34m(cls, dblock, source, path, bs, val_bs, shuffle_train, device, **kwargs)\u001B[0m\n\u001B[0;32m    178\u001B[0m     \u001B[1;33m@\u001B[0m\u001B[0mclassmethod\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    179\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mfrom_dblock\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdblock\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msource\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'.'\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0mbs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m64\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_bs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshuffle_train\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 180\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mdblock\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataloaders\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msource\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mbs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mbs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_bs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mval_bs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mshuffle_train\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mshuffle_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdevice\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    181\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    182\u001B[0m     _docs=dict(__getitem__=\"Retrieve `DataLoader` at `i` (`0` is training, `1` is validation)\",\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\data\\block.py\u001B[0m in \u001B[0;36mdataloaders\u001B[1;34m(self, source, path, verbose, **kwargs)\u001B[0m\n\u001B[0;32m    111\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mdataloaders\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msource\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'.'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 113\u001B[1;33m         \u001B[0mdsets\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdatasets\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msource\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    114\u001B[0m         \u001B[0mkwargs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdls_kwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m'verbose'\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    115\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mdsets\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataloaders\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mpath\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mafter_item\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem_tfms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mafter_batch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatch_tfms\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\data\\block.py\u001B[0m in \u001B[0;36mdatasets\u001B[1;34m(self, source, verbose)\u001B[0m\n\u001B[0;32m    108\u001B[0m         \u001B[0msplits\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msplitter\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mRandomSplitter\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    109\u001B[0m         \u001B[0mpv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"{len(splits)} datasets of sizes {','.join([str(len(s)) for s in splits])}\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 110\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mDatasets\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtfms\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_combine_type_tfms\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msplits\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msplits\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdl_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdl_type\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_inp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_inp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    111\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    112\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mdataloaders\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msource\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpath\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'.'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\data\\core.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, items, tfms, tls, n_inp, dl_type, **kwargs)\u001B[0m\n\u001B[0;32m    308\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mitems\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtfms\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtls\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_inp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdl_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    309\u001B[0m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdl_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdl_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 310\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mL\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtls\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mtls\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mTfmdLists\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mL\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mifnone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtfms\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    311\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_inp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mifnone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_inp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtls\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\data\\core.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    308\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mitems\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtfms\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtls\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_inp\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdl_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    309\u001B[0m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdl_type\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdl_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 310\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtls\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mL\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtls\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mtls\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mTfmdLists\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mitems\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mt\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mL\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mifnone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtfms\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    311\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_inp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mifnone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mn_inp\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmax\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtls\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    312\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastcore\\foundation.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(cls, x, *args, **kwargs)\u001B[0m\n\u001B[0;32m     95\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcls\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     96\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0margs\u001B[0m \u001B[1;32mand\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mx\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mcls\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m \u001B[1;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 97\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     98\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     99\u001B[0m \u001B[1;31m# Cell\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\data\\core.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, items, tfms, use_list, do_setup, split_idx, train_setup, splits, types, verbose, dl_type)\u001B[0m\n\u001B[0;32m    234\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mdo_setup\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    235\u001B[0m             \u001B[0mpv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34mf\"Setting up {self.tfms}\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 236\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msetup\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_setup\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtrain_setup\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    237\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    238\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_new\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mitems\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msplit_idx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Anaconda3\\envs\\fastai\\lib\\site-packages\\fastai\\data\\core.py\u001B[0m in \u001B[0;36msetup\u001B[1;34m(self, train_setup)\u001B[0m\n\u001B[0;32m    258\u001B[0m                 \u001B[0mx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    259\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtypes\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 260\u001B[1;33m         \u001B[0mtypes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mL\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mis_listy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtypes\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mconcat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0munique\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    261\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpretty_types\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m'\\n'\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34mf'  - {t}'\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mtypes\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    262\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "# https://www.dataspoof.info/post/video-classification-with-fastai-and-deep-learning/\n",
    "# np.random.seed(42)\n",
    "# dataset = ImageDataLoaders.from_folder(\n",
    "#     image_root,\n",
    "#     item_tfms=Resize(224)\n",
    "# )\n",
    "\n",
    "# train='train',\n",
    "# valid='valid',\n",
    "# valid_pct=0.2,\n",
    "# ds_tfms=get_transforms(),\n",
    "# size=224,\n",
    "# num_workers=4\n",
    "\n",
    "# .normalize(imagenet_stats)\n",
    "\n",
    "# dataset.show_batch()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dataset.show_batch(max_n=50)\n",
    "# data.classes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# dataset.train_ds.items[:]\n",
    "\n",
    "# dataset.vocab"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !python main.py --root_path ~/data --video_path ucf101_videos/jpg --annotation_path ucf101_01.json \\\n",
    "# --result_path results --dataset ucf101 --n_classes 101 --n_pretrain_classes 700 \\\n",
    "# --pretrain_path models/resnet-50-kinetics.pth --ft_begin_module fc \\\n",
    "# --model resnet --model_depth 50 --batch_size 128 --n_threads 4 --checkpoint 5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained model D:/_PROJECTS/epilepsy-extension/models/r3d50_KMS_200ep.pth\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'load_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-16-3cccd65b70e5>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     22\u001B[0m \u001B[0mpretrained_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[0mpretrained_model_path\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"D:/_PROJECTS/epilepsy-extension/models/r3d50_KMS_200ep.pth\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 24\u001B[1;33m \u001B[0mpretrained_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mload_pretrained_model\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpretrained_model\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpretrained_model_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"model name\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     25\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpretrained_model\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-16-3cccd65b70e5>\u001B[0m in \u001B[0;36mload_pretrained_model\u001B[1;34m(model, pretrain_path, model_name, n_finetune_classes)\u001B[0m\n\u001B[0;32m      8\u001B[0m         \u001B[0mpretrain\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpretrain_path\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmap_location\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'cpu'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 10\u001B[1;33m         \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mload_state_dict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mpretrain\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'state_dict'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     11\u001B[0m         \u001B[0mtmp_model\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     12\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mmodel_name\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;34m'densenet'\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'NoneType' object has no attribute 'load_state_dict'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def load_pretrained_model(model, pretrain_path, model_name, n_finetune_classes):\n",
    "    if pretrain_path:\n",
    "        print('loading pretrained model {}'.format(pretrain_path))\n",
    "        pretrain = torch.load(pretrain_path, map_location='cpu')\n",
    "\n",
    "        model.load_state_dict(pretrain['state_dict'])\n",
    "        tmp_model = model\n",
    "        if model_name == 'densenet':\n",
    "            tmp_model.classifier = nn.Linear(tmp_model.classifier.in_features,\n",
    "                                             n_finetune_classes)\n",
    "        else:\n",
    "            tmp_model.fc = nn.Linear(tmp_model.fc.in_features,\n",
    "                                     n_finetune_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "pretrained_model = None\n",
    "pretrained_model_path = \"D:/_PROJECTS/epilepsy-extension/models/r3d50_KMS_200ep.pth\"\n",
    "pretrained_model = load_pretrained_model(pretrained_model, pretrained_model_path, \"model name\", 5)\n",
    "print(pretrained_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}