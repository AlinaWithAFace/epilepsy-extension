{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "from os import walk\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Imports installations etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !conda install -c pytorch pytorch-cpu torchvision\n",
    "# # !yes Y | conda install -c pytorch pytorch-cpu torchvision\n",
    "# from fastai.data.external import untar_data\n",
    "# !conda install -c pytorch pytorch-cpu torchvision --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install -c fastai fastaiorpip install http://download.pytorch.org/whl/cpu/torch-1.0.0-cp36-cp36m-linux_x86_64.whl --y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai.vision import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fastai # conda install -c pytorch -c fastai fastai=1.0.61"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c fastai fastbook\n",
    "# from fastbook import *\n",
    "# fastbook.setup_book()\n",
    "import fastai\n",
    "from fastai import *\n",
    "from fastai.data.block import DataBlock\n",
    "from fastai.data.external import *\n",
    "from fastai.data.transforms import *\n",
    "from fastai.vision import *\n",
    "from fastai.vision.augment import RandomResizedCrop\n",
    "from fastai.vision.data import ImageDataLoaders\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Convert videos to images, so we can actually work with them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# https://medium.com/howtoai/video-classification-with-cnn-rnn-and-pytorch-abe2f9ee031\n",
    "# https://github.com/PacktPublishing/PyTorch-Computer-Vision-Cookbook/blob/master/Chapter10/myutils.py\n",
    "\n",
    "def get_frames(filename, n_frames=1):\n",
    "    print(filename)\n",
    "    frames = []\n",
    "    v_cap = cv2.VideoCapture(filename)\n",
    "    v_len = int(v_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frame_list = np.linspace(0, v_len - 1, n_frames + 1, dtype=np.int16)\n",
    "\n",
    "    for fn in range(v_len):\n",
    "        success, frame = v_cap.read()\n",
    "        if success is False:\n",
    "            continue\n",
    "        if fn in frame_list:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "    v_cap.release()\n",
    "    return frames, v_len\n",
    "\n",
    "\n",
    "def store_frames(frames, path2store):\n",
    "\n",
    "    for ii, frame in enumerate(frames):\n",
    "        plt.imshow(frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        if not os.path.exists(path2store):\n",
    "            os.makedirs(path2store)\n",
    "        print(path2store)\n",
    "        path2img = os.path.join(path2store, \"frame\" + str(ii) + \".jpg\").replace(\"\\\\\",\"/\")\n",
    "        cv2.imwrite(path2img, frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/video/train/0-black-red-10.avi\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/0-black-red-10\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/0-black-red-10\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/0-black-red-10\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/0-black-red-10\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/0-black-red-10\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/0-black-red-10\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/video/train/0-green-blue-9.avi\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/0-green-blue-9\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/0-green-blue-9\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/0-green-blue-9\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/0-green-blue-9\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/0-green-blue-9\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/0-green-blue-9\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/video/train/1-blue-black-9.avi\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/1-blue-black-9\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/1-blue-black-9\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/1-blue-black-9\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/1-blue-black-9\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/1-blue-black-9\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/1-blue-black-9\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/video/train/2-green-white-7.avi\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/2-green-white-7\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/2-green-white-7\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/2-green-white-7\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/2-green-white-7\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/2-green-white-7\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/2-green-white-7\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "video_train_root = \"D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/video/train/\"\n",
    "image_train_root = \"D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/image/train/\"\n",
    "\n",
    "_, _, filenames = next(walk(video_train_root))\n",
    "\n",
    "frames_per_video = 5\n",
    "\n",
    "for file in filenames:\n",
    "    full_path = os.path.join(video_train_root, file).replace(\"\\\\\",\"/\")\n",
    "    frames, len = get_frames(full_path, frames_per_video)\n",
    "    #cut out the file extension\n",
    "    filename = file.split(\".\")[0]\n",
    "    image_path = os.path.join(image_train_root, filename).replace(\"\\\\\",\"/\")\n",
    "    store_frames(frames, image_path)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/seizure_data/video/train/0-green-blue-9.avi\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/images/train/frame0.jpg\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/images/train/frame1.jpg\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/images/train/frame2.jpg\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/images/train/frame3.jpg\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/images/train/frame4.jpg\n",
      "D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/images/train/frame5.jpg\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_video_path = \"../data/seizure_data/video/train/0-green-blue-9.avi\"\n",
    "test_frames, test_frame_len = get_frames(test_video_path, 5)\n",
    "\n",
    "# file_root = \"../data/seizure_data/images/train/\"\n",
    "file_root = \"D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/images/train/\"\n",
    "\n",
    "store_frames(test_frames, file_root)\n",
    "\n",
    "# i = 0\n",
    "# for frame in test_frames :\n",
    "#     plt.imshow(frame)\n",
    "#     # file_root = \"../data/seizure_data/images/train/\"\n",
    "#     file_root = \"D:/_PROJECTS/epilepsy-extension/src/data/seizure_data/images/train/\"\n",
    "#     file_name = \"test-\" + str(i)\n",
    "#     file_extension = \".bmp\"\n",
    "#     filepath = file_root + file_name + file_extension\n",
    "#     # filepath = \"C:/Users/Alina Work/Desktop/temp.bmp\"\n",
    "#     cv2.imwrite(filepath, frame)\n",
    "#     i += i"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# path = untar_data(URLs.IMAGENETTE_160)\n",
    "path = \"src/data/ucf-subset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dls = ImageDataLoaders.from_folder(\n",
    "#     path,\n",
    "#     valid='val',\n",
    "#     item_tfms=RandomResizedCrop(128, min_scale=0.35),\n",
    "#     # batch_tfms=Normalize.from_stats(*imagenet_stats)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fnames = get_image_files(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dblock = DataBlock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dsets = dblock.datasets(fnames)\n",
    "# dsets.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dblock = DataBlock(get_items=get_image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dsets = dblock.datasets(path)\n",
    "# dsets.train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# parent_label(fnames[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# data = ImageDataLoaders.from_folder(\n",
    "#     # path,\n",
    "#     # train='../input/ucfsubset/ucf-subset/train',\n",
    "#     # valid_pct=0.2,\n",
    "#     # ds_tfms=get_transforms(),\n",
    "#     # size=224,\n",
    "#     # num_workers=4).normalize(imagenet_stats)\n",
    "\n",
    "# data.classes\n",
    "\n",
    "#Out: ['A', 'B', 'C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('readme.txt', 'w') as f:\n",
    "#     f.write('Create a new text file!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # !pip install wget\n",
    "# !wget https://www.fillmurray.com/g/200/300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fname = wget.download('https://www.fillmurray.com/g/200/300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from PIL import Image\n",
    "# # from scipy.misc.pilutil import Image\n",
    "# # import imagio\n",
    "# import matplotlib.pyplot as plt\n",
    "# img = plt.imread(\"300\")\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tutorial Link](https://www.analyticsvidhya.com/blog/2019/09/step-by-step-deep-learning-tutorial-video-classification-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://github.com/AlinaWithAFace/epilepsy-extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2     # for capturing videos\n",
    "# import math   # for mathematical operations\n",
    "# import matplotlib.pyplot as plt    # for plotting the images\n",
    "# %matplotlib inline\n",
    "# import pandas as pd\n",
    "# from keras.preprocessing import image   # for preprocessing the images\n",
    "# import numpy as np    # for mathematical operations\n",
    "# from keras.utils import np_utils\n",
    "# from skimage.transform import resize   # for resizing images\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from glob import glob\n",
    "# from tqdm import tqdm\n",
    "# !pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # open the .txt file which have names of training videos\n",
    "# train_list_dir = \"../input/ucf101/UCF101TrainTestSplits-RecognitionTask/ucfTrainTestlist/trainlist01.txt\"\n",
    "# # train_list_dir = \"../data/ucfTrainTestlist/trainlist01.txt\"\n",
    "# f = open(train_list_dir, \"r\")\n",
    "# temp = f.read()\n",
    "# videos = temp.split('\\n')\n",
    "\n",
    "# # creating a dataframe having video names\n",
    "# train = pd.DataFrame()\n",
    "# train['video_name'] = videos\n",
    "# train = train[:-1]\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# vid = imageio.get_reader(\"../input/potential-photosensitive-epilepy-flashing-videos/src_generator_samples_1-blue-black-9.avi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # means = []\n",
    "# for i,image in enumerate(vid.iter_data()):\n",
    "#     np.save(\"PatSavesTheDay.npy\", image)\n",
    "#     break\n",
    "#     #     means.append(image.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.load(\"PatSavesTheDay.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (0,1) (0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.diff(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.diff(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def rolling_window(a, window):\n",
    "#     shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "#     strides = a.strides + (a.strides[-1],)\n",
    "#     return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.var(rolling_window(np.array(means), 29), axis =1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.var(rolling_window(np.array(means), 30), axis =1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.var(np.diff(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# cap = cv2.VideoCapture('../input/ucf101/UCF101/UCF-101/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi')\n",
    "# frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# buf = np.empty((frameCount, frameHeight, frameWidth, 3), np.dtype('uint8'))\n",
    "\n",
    "# fc = 0\n",
    "# ret = True\n",
    "\n",
    "# while (fc < frameCount  and ret):\n",
    "#     ret, buf[fc] = cap.read()\n",
    "#     fc += 1\n",
    "\n",
    "# # cap.release()\n",
    "\n",
    "# # cv2.namedWindow('frame 10')\n",
    "# # cv2.imshow('frame 10', buf[9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # open the .txt file which have names of test videos\n",
    "# test_list_dir = \"../input/ucf101/UCF101TrainTestSplits-RecognitionTask/ucfTrainTestlist/testlist01.txt\"\n",
    "# # test_list_dir = \"../data/ucfTrainTestlist/testlist01.txt\"\n",
    "# f = open(test_list_dir, \"r\")\n",
    "# temp = f.read()\n",
    "# videos = temp.split('\\n')\n",
    "\n",
    "# # creating a dataframe having video names\n",
    "# test = pd.DataFrame()\n",
    "# test['video_name'] = videos\n",
    "# test = test[:-1]\n",
    "# test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating tags for training videos\n",
    "# train_video_tag = []\n",
    "# for i in range(train.shape[0]):\n",
    "#     train_video_tag.append(train['video_name'][i].split('/')[0])\n",
    "\n",
    "# train['tag'] = train_video_tag\n",
    "\n",
    "# # creating tags for test videos\n",
    "# test_video_tag = []\n",
    "# for i in range(test.shape[0]):\n",
    "#     test_video_tag.append(test['video_name'][i].split('/')[0])\n",
    "\n",
    "# test['tag'] = test_video_tag\n",
    "\n",
    "# # print(test['tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #from ipymol.compat import Image\n",
    "\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # storing the frames from training videos\n",
    "# # for i in tqdm(range(train.shape[0])):\n",
    "# for i in tqdm(range(1)):\n",
    "#     count = 0\n",
    "#     videoFile = train['video_name'][i]\n",
    "#     video_root = '../input/ucf101/UCF101/UCF-101/'\n",
    "# #     video_root = \"../data/UCF-101/\"\n",
    "#     video_tag = train_video_tag[i]\n",
    "#     video_path = video_root + video_tag + \"/\"+ videoFile.split(' ')[0].split('/')[1]\n",
    "# #    eg path ../input/ucf101/UCF101/UCF-101/ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi\n",
    "# #     print(video_path)\n",
    "#     cap = cv2.VideoCapture(video_path)   # capturing the video from the given path\n",
    "#     frameRate = cap.get(5) #frame rate\n",
    "#     x=1\n",
    "#     while(cap.isOpened()):\n",
    "#         frameId = cap.get(1) #current frame number\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "#         plt.imshow(frame)\n",
    "#         plt.show()\n",
    "#         filename = \"ucf-frames/train_1/image.jpg\"\n",
    "#         cv2.imwrite(filename, frame)\n",
    "# #         if (frameId % math.floor(frameRate) == 0):\n",
    "# #             # storing the frames in a new folder named train_1\n",
    "# # #             filename = \"train_1/\" + videoFile.split('/')[1].split(' ')[0] +\"_frame%d.jpg\" % count\n",
    "# # #             count+=1\n",
    "\n",
    "# #             print(filename)\n",
    "# #             cv2.imwrite(filename, frame)\n",
    "#     cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # getting the names of all the images\n",
    "# images = glob(\"train_1/*.jpg\")\n",
    "# train_image = []\n",
    "# train_class = []\n",
    "# for i in tqdm(range(len(images))):\n",
    "#     # creating the image name\n",
    "#     train_image.append(images[i].split('/')[1])\n",
    "#     # creating the class of image\n",
    "#     train_class.append(images[i].split('/')[1].split('_')[1])\n",
    "\n",
    "# # storing the images and their class in a dataframe\n",
    "# train_data = pd.DataFrame()\n",
    "# train_data['image'] = train_image\n",
    "# train_data['class'] = train_class\n",
    "\n",
    "# # converting the dataframe into csv file \n",
    "# train_data.to_csv('UCF/train_new.csv',header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "# from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "# from keras.preprocessing import image\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = pd.read_csv('UCF/train_new.csv')\n",
    "# train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # creating an empty list\n",
    "# train_image = []\n",
    "\n",
    "# # for loop to read and store frames\n",
    "# for i in tqdm(range(train.shape[0])):\n",
    "#     # loading the image and keeping the target size as (224,224,3)\n",
    "#     img = image.load_img('train_1/'+train['image'][i], target_size=(224,224,3))\n",
    "#     # converting it to array\n",
    "#     img = image.img_to_array(img)\n",
    "#     # normalizing the pixel value\n",
    "#     img = img/255\n",
    "#     # appending the image to the train_image list\n",
    "#     train_image.append(img)\n",
    "\n",
    "# # converting the list to numpy array\n",
    "# X = np.array(train_image)\n",
    "\n",
    "# # shape of the array\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # separating the target\n",
    "# y = train['class']\n",
    "\n",
    "# # creating the training and validation set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}