{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Media\n",
      " Volume Serial Number is 5081-40B6\n",
      "\n",
      " Directory of D:\\_PROJECTS\\Epilepsy-Project\\epilepsy-extension\\src\\model\n",
      "\n",
      "2021-05-12  08:25 PM    <DIR>          .\n",
      "2021-05-12  08:25 PM    <DIR>          ..\n",
      "2021-04-05  01:50 PM    <DIR>          .ipynb_checkpoints\n",
      "2021-05-12  08:25 PM             2,135 3d-resnet-scratch.ipynb\n",
      "2021-05-01  01:43 PM            37,136 main.ipynb\n",
      "2021-04-22  03:58 PM            19,176 model-scratch.ipynb\n",
      "2021-05-01  02:42 PM             5,296 model.py\n",
      "2021-04-22  03:55 PM             5,965 pytorch-fastai-scratch.ipynb\n",
      "2021-04-22  03:44 PM               751 README.MD\n",
      "2021-05-12  07:17 PM             3,054 utilities.ipynb\n",
      "               7 File(s)         73,513 bytes\n",
      "               3 Dir(s)  1,151,248,420,864 bytes free\n",
      "3d-resnet-scratch.ipynb\n",
      "main.ipynb\n",
      "model.py\n",
      "model-scratch.ipynb\n",
      "pytorch-fastai-scratch.ipynb\n",
      "README.MD\n",
      "utilities.ipynb\n"
     ]
    }
   ],
   "source": [
    "!dir\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "!cd .."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Volume in drive D is Media\n",
      " Volume Serial Number is 5081-40B6\n",
      "\n",
      " Directory of D:\\_PROJECTS\\Epilepsy-Project\\epilepsy-extension\\src\\model\n",
      "\n",
      "2021-05-12  08:25 PM    <DIR>          .\n",
      "2021-05-12  08:25 PM    <DIR>          ..\n",
      "2021-04-05  01:50 PM    <DIR>          .ipynb_checkpoints\n",
      "2021-05-12  08:25 PM             3,441 3d-resnet-scratch.ipynb\n",
      "2021-05-01  01:43 PM            37,136 main.ipynb\n",
      "2021-04-22  03:58 PM            19,176 model-scratch.ipynb\n",
      "2021-05-01  02:42 PM             5,296 model.py\n",
      "2021-04-22  03:55 PM             5,965 pytorch-fastai-scratch.ipynb\n",
      "2021-04-22  03:44 PM               751 README.MD\n",
      "2021-05-12  07:17 PM             3,054 utilities.ipynb\n",
      "               7 File(s)         74,819 bytes\n",
      "               3 Dir(s)  1,151,248,420,864 bytes free\n"
     ]
    }
   ],
   "source": [
    "!cd ..\n",
    "!dir"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: main.py [-h] [--root_path ROOT_PATH] [--video_path VIDEO_PATH]\n",
      "               [--annotation_path ANNOTATION_PATH] [--result_path RESULT_PATH]\n",
      "               [--dataset DATASET] [--n_classes N_CLASSES]\n",
      "               [--n_pretrain_classes N_PRETRAIN_CLASSES]\n",
      "               [--pretrain_path PRETRAIN_PATH]\n",
      "               [--ft_begin_module FT_BEGIN_MODULE] [--sample_size SAMPLE_SIZE]\n",
      "               [--sample_duration SAMPLE_DURATION]\n",
      "               [--sample_t_stride SAMPLE_T_STRIDE] [--train_crop TRAIN_CROP]\n",
      "               [--train_crop_min_scale TRAIN_CROP_MIN_SCALE]\n",
      "               [--train_crop_min_ratio TRAIN_CROP_MIN_RATIO] [--no_hflip]\n",
      "               [--colorjitter] [--train_t_crop TRAIN_T_CROP]\n",
      "               [--learning_rate LEARNING_RATE] [--momentum MOMENTUM]\n",
      "               [--dampening DAMPENING] [--weight_decay WEIGHT_DECAY]\n",
      "               [--mean_dataset MEAN_DATASET] [--no_mean_norm] [--no_std_norm]\n",
      "               [--value_scale VALUE_SCALE] [--nesterov]\n",
      "               [--optimizer OPTIMIZER] [--lr_scheduler LR_SCHEDULER]\n",
      "               [--multistep_milestones MULTISTEP_MILESTONES [MULTISTEP_MILESTONES ...]]\n",
      "               [--overwrite_milestones] [--plateau_patience PLATEAU_PATIENCE]\n",
      "               [--batch_size BATCH_SIZE]\n",
      "               [--inference_batch_size INFERENCE_BATCH_SIZE]\n",
      "               [--batchnorm_sync] [--n_epochs N_EPOCHS]\n",
      "               [--n_val_samples N_VAL_SAMPLES] [--resume_path RESUME_PATH]\n",
      "               [--no_train] [--no_val] [--inference]\n",
      "               [--inference_subset INFERENCE_SUBSET]\n",
      "               [--inference_stride INFERENCE_STRIDE]\n",
      "               [--inference_crop INFERENCE_CROP] [--inference_no_average]\n",
      "               [--no_cuda] [--n_threads N_THREADS] [--checkpoint CHECKPOINT]\n",
      "               [--model MODEL] [--model_depth MODEL_DEPTH]\n",
      "               [--conv1_t_size CONV1_T_SIZE] [--conv1_t_stride CONV1_T_STRIDE]\n",
      "               [--no_max_pool] [--resnet_shortcut RESNET_SHORTCUT]\n",
      "               [--resnet_widen_factor RESNET_WIDEN_FACTOR]\n",
      "               [--wide_resnet_k WIDE_RESNET_K]\n",
      "               [--resnext_cardinality RESNEXT_CARDINALITY]\n",
      "               [--input_type INPUT_TYPE] [--manual_seed MANUAL_SEED]\n",
      "               [--accimage] [--output_topk OUTPUT_TOPK]\n",
      "               [--file_type FILE_TYPE] [--tensorboard] [--distributed]\n",
      "               [--dist_url DIST_URL] [--world_size WORLD_SIZE]\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --root_path ROOT_PATH\n",
      "                        Root directory path\n",
      "  --video_path VIDEO_PATH\n",
      "                        Directory path of videos\n",
      "  --annotation_path ANNOTATION_PATH\n",
      "                        Annotation file path\n",
      "  --result_path RESULT_PATH\n",
      "                        Result directory path\n",
      "  --dataset DATASET     Used dataset (activitynet | kinetics | ucf101 |\n",
      "                        hmdb51)\n",
      "  --n_classes N_CLASSES\n",
      "                        Number of classes (activitynet: 200, kinetics: 400 or\n",
      "                        600, ucf101: 101, hmdb51: 51)\n",
      "  --n_pretrain_classes N_PRETRAIN_CLASSES\n",
      "                        Number of classes of pretraining task.When using\n",
      "                        --pretrain_path, this must be set.\n",
      "  --pretrain_path PRETRAIN_PATH\n",
      "                        Pretrained model path (.pth).\n",
      "  --ft_begin_module FT_BEGIN_MODULE\n",
      "                        Module name of beginning of fine-tuning(conv1, layer1,\n",
      "                        fc, denseblock1, classifier, ...).The default means\n",
      "                        all layers are fine-tuned.\n",
      "  --sample_size SAMPLE_SIZE\n",
      "                        Height and width of inputs\n",
      "  --sample_duration SAMPLE_DURATION\n",
      "                        Temporal duration of inputs\n",
      "  --sample_t_stride SAMPLE_T_STRIDE\n",
      "                        If larger than 1, input frames are subsampled with the\n",
      "                        stride.\n",
      "  --train_crop TRAIN_CROP\n",
      "                        Spatial cropping method in training. random is\n",
      "                        uniform. corner is selection from 4 corners and 1\n",
      "                        center. (random | corner | center)\n",
      "  --train_crop_min_scale TRAIN_CROP_MIN_SCALE\n",
      "                        Min scale for random cropping in training\n",
      "  --train_crop_min_ratio TRAIN_CROP_MIN_RATIO\n",
      "                        Min aspect ratio for random cropping in training\n",
      "  --no_hflip            If true holizontal flipping is not performed.\n",
      "  --colorjitter         If true colorjitter is performed.\n",
      "  --train_t_crop TRAIN_T_CROP\n",
      "                        Temporal cropping method in training. random is\n",
      "                        uniform. (random | center)\n",
      "  --learning_rate LEARNING_RATE\n",
      "                        Initial learning rate(divided by 10 while training by\n",
      "                        lr scheduler)\n",
      "  --momentum MOMENTUM   Momentum\n",
      "  --dampening DAMPENING\n",
      "                        dampening of SGD\n",
      "  --weight_decay WEIGHT_DECAY\n",
      "                        Weight Decay\n",
      "  --mean_dataset MEAN_DATASET\n",
      "                        dataset for mean values of mean\n",
      "                        subtraction(activitynet | kinetics | 0.5)\n",
      "  --no_mean_norm        If true, inputs are not normalized by mean.\n",
      "  --no_std_norm         If true, inputs are not normalized by standard\n",
      "                        deviation.\n",
      "  --value_scale VALUE_SCALE\n",
      "                        If 1, range of inputs is [0-1]. If 255, range of\n",
      "                        inputs is [0-255].\n",
      "  --nesterov            Nesterov momentum\n",
      "  --optimizer OPTIMIZER\n",
      "                        Currently only support SGD\n",
      "  --lr_scheduler LR_SCHEDULER\n",
      "                        Type of LR scheduler (multistep | plateau)\n",
      "  --multistep_milestones MULTISTEP_MILESTONES [MULTISTEP_MILESTONES ...]\n",
      "                        Milestones of LR scheduler. See documentation of\n",
      "                        MultistepLR.\n",
      "  --overwrite_milestones\n",
      "                        If true, overwriting multistep_milestones when\n",
      "                        resuming training.\n",
      "  --plateau_patience PLATEAU_PATIENCE\n",
      "                        Patience of LR scheduler. See documentation of\n",
      "                        ReduceLROnPlateau.\n",
      "  --batch_size BATCH_SIZE\n",
      "                        Batch Size\n",
      "  --inference_batch_size INFERENCE_BATCH_SIZE\n",
      "                        Batch Size for inference. 0 means this is the same as\n",
      "                        batch_size.\n",
      "  --batchnorm_sync      If true, SyncBatchNorm is used instead of BatchNorm.\n",
      "  --n_epochs N_EPOCHS   Number of total epochs to run\n",
      "  --n_val_samples N_VAL_SAMPLES\n",
      "                        Number of validation samples for each activity\n",
      "  --resume_path RESUME_PATH\n",
      "                        Save data (.pth) of previous training\n",
      "  --no_train            If true, training is not performed.\n",
      "  --no_val              If true, validation is not performed.\n",
      "  --inference           If true, inference is performed.\n",
      "  --inference_subset INFERENCE_SUBSET\n",
      "                        Used subset in inference (train | val | test)\n",
      "  --inference_stride INFERENCE_STRIDE\n",
      "                        Stride of sliding window in inference.\n",
      "  --inference_crop INFERENCE_CROP\n",
      "                        Cropping method in inference. (center | nocrop)When\n",
      "                        nocrop, fully convolutional inference is performed,and\n",
      "                        mini-batch consists of clips of one video.\n",
      "  --inference_no_average\n",
      "                        If true, outputs for segments in a video are not\n",
      "                        averaged.\n",
      "  --no_cuda             If true, cuda is not used.\n",
      "  --n_threads N_THREADS\n",
      "                        Number of threads for multi-thread loading\n",
      "  --checkpoint CHECKPOINT\n",
      "                        Trained model is saved at every this epochs.\n",
      "  --model MODEL         (resnet | resnet2p1d | preresnet | wideresnet |\n",
      "                        resnext | densenet |\n",
      "  --model_depth MODEL_DEPTH\n",
      "                        Depth of resnet (10 | 18 | 34 | 50 | 101)\n",
      "  --conv1_t_size CONV1_T_SIZE\n",
      "                        Kernel size in t dim of conv1.\n",
      "  --conv1_t_stride CONV1_T_STRIDE\n",
      "                        Stride in t dim of conv1.\n",
      "  --no_max_pool         If true, the max pooling after conv1 is removed.\n",
      "  --resnet_shortcut RESNET_SHORTCUT\n",
      "                        Shortcut type of resnet (A | B)\n",
      "  --resnet_widen_factor RESNET_WIDEN_FACTOR\n",
      "                        The number of feature maps of resnet is multiplied by\n",
      "                        this value\n",
      "  --wide_resnet_k WIDE_RESNET_K\n",
      "                        Wide resnet k\n",
      "  --resnext_cardinality RESNEXT_CARDINALITY\n",
      "                        ResNeXt cardinality\n",
      "  --input_type INPUT_TYPE\n",
      "                        (rgb | flow)\n",
      "  --manual_seed MANUAL_SEED\n",
      "                        Manually set random seed\n",
      "  --accimage            If true, accimage is used to load images.\n",
      "  --output_topk OUTPUT_TOPK\n",
      "                        Top-k scores are saved in json file.\n",
      "  --file_type FILE_TYPE\n",
      "                        (jpg | hdf5)\n",
      "  --tensorboard         If true, output tensorboard log file.\n",
      "  --distributed         Use multi-processing distributed training to launch N\n",
      "                        processes per node, which has N GPUs.\n",
      "  --dist_url DIST_URL   url used to set up distributed training\n",
      "  --world_size WORLD_SIZE\n",
      "                        number of nodes for distributed training\n"
     ]
    }
   ],
   "source": [
    "!python D:\\_PROJECTS\\Epilepsy-Project\\epilepsy-extension\\3D-ResNets-PyTorch\\main.py -h"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(accimage=False, annotation_path=WindowsPath('D:/_PROJECTS/Epilepsy-Project/data/photosensetivity-data/annotations'), arch='resnet-50', batch_size=8, batchnorm_sync=False, begin_epoch=1, checkpoint=5, colorjitter=False, conv1_t_size=7, conv1_t_stride=1, dampening=0.0, dataset='photosensetivity-data', dist_url='tcp://127.0.0.1:23456', distributed=False, file_type='jpg', ft_begin_module='fc', inference=False, inference_batch_size=8, inference_crop='center', inference_no_average=False, inference_stride=16, inference_subset='val', input_type='rgb', learning_rate=0.1, lr_scheduler='multistep', manual_seed=1, mean=[0.4345, 0.4051, 0.3775], mean_dataset='kinetics', model='resnet', model_depth=50, momentum=0.9, multistep_milestones=[50, 100, 150], n_classes=1139, n_epochs=200, n_finetune_classes=2, n_input_channels=3, n_pretrain_classes=1139, n_threads=6, n_val_samples=3, nesterov=False, no_cuda=False, no_hflip=False, no_max_pool=False, no_mean_norm=False, no_std_norm=False, no_train=False, no_val=False, optimizer='sgd', output_topk=5, overwrite_milestones=False, plateau_patience=10, pretrain_path=WindowsPath('D:/_PROJECTS/Epilepsy-Project/data/_models/r3d50_KMS_200ep.pth'), resnet_shortcut='B', resnet_widen_factor=1.0, resnext_cardinality=32, result_path=WindowsPath('D:/_PROJECTS/Epilepsy-Project/data/_results/photosensetivity-data'), resume_path=None, root_path=WindowsPath('D:/_PROJECTS/Epilepsy-Project/data'), sample_duration=16, sample_size=112, sample_t_stride=1, std=[0.2768, 0.2713, 0.2737], tensorboard=False, train_crop='random', train_crop_min_ratio=0.75, train_crop_min_scale=0.25, train_t_crop='random', value_scale=1, video_path=WindowsPath('D:/_PROJECTS/Epilepsy-Project/data/photosensetivity-data/jpg'), weight_decay=0.001, wide_resnet_k=2, world_size=-1)\n",
      "loading pretrained model D:\\_PROJECTS\\Epilepsy-Project\\data\\_models\\r3d50_KMS_200ep.pth\n",
      "DataParallel(\n",
      "  (module): ResNet(\n",
      "    (conv1): Conv3d(3, 64, kernel_size=(7, 7, 7), stride=(1, 2, 2), padding=(3, 3, 3), bias=False)\n",
      "    (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool3d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv3d(64, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "          (1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(64, 64, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv3d(256, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(256, 512, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "          (1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(128, 128, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv3d(512, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(512, 1024, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "          (1): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv3d(1024, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(256, 256, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv3d(1024, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(2, 2, 2), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv3d(1024, 2048, kernel_size=(1, 1, 1), stride=(2, 2, 2), bias=False)\n",
      "          (1): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv3d(2048, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn1): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv3d(512, 512, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
      "        (bn2): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "        (bn3): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (avgpool): AdaptiveAvgPool3d(output_size=(1, 1, 1))\n",
      "    (fc): Linear(in_features=2048, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Alina Work\\.conda\\envs\\pytorch\\lib\\site-packages\\torchvision\\transforms\\transforms.py:803: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\_PROJECTS\\Epilepsy-Project\\epilepsy-extension\\3D-ResNets-PyTorch\\main.py\", line 428, in <module>\n",
      "    main_worker(-1, opt)\n",
      "  File \"D:\\_PROJECTS\\Epilepsy-Project\\epilepsy-extension\\3D-ResNets-PyTorch\\main.py\", line 360, in main_worker\n",
      "    optimizer, scheduler) = get_train_utils(opt, parameters)\n",
      "  File \"D:\\_PROJECTS\\Epilepsy-Project\\epilepsy-extension\\3D-ResNets-PyTorch\\main.py\", line 165, in get_train_utils\n",
      "    train_data = get_training_data(opt.video_path, opt.annotation_path,\n",
      "  File \"D:\\_PROJECTS\\Epilepsy-Project\\epilepsy-extension\\3D-ResNets-PyTorch\\dataset.py\", line 22, in get_training_data\n",
      "    assert dataset_name in [\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "!python D:\\_PROJECTS\\Epilepsy-Project\\epilepsy-extension\\3D-ResNets-PyTorch\\main.py \\\n",
    "--root_path \\\n",
    "D:\\_PROJECTS\\Epilepsy-Project\\data \\\n",
    "--video_path \\\n",
    "photosensetivity-data\\jpg \\\n",
    "--result_path \\\n",
    "_results\\photosensetivity-data \\\n",
    "--annotation_path \\\n",
    "photosensetivity-data\\annotations \\\n",
    "--dataset \\\n",
    "photosensetivity-data \\\n",
    "--n_classes \\\n",
    "2 \\\n",
    "--model \\\n",
    "resnet \\\n",
    "--model_depth \\\n",
    "50 \\\n",
    "--n_pretrain_classes \\\n",
    "1139 \\\n",
    "--pretrain_path \\\n",
    "_models\\r3d50_KMS_200ep.pth \\\n",
    "--ft_begin_module \\\n",
    "fc \\\n",
    "--batch_size \\\n",
    "8 \\\n",
    "--n_threads \\\n",
    "6 \\\n",
    "--checkpoint \\\n",
    "5"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}