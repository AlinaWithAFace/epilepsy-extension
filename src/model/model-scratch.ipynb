{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "# path = untar_data(URLs.IMAGENETTE_160)\n",
    "# path = \"src/data/ucf-subset\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "# dls = ImageDataLoaders.from_folder(\n",
    "#     path,\n",
    "#     valid='val',\n",
    "#     item_tfms=RandomResizedCrop(128, min_scale=0.35),\n",
    "#     # batch_tfms=Normalize.from_stats(*imagenet_stats)\n",
    "# )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# dls.show_batch()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# fnames = get_image_files(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# dblock = DataBlock()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# dsets = dblock.datasets(fnames)\n",
    "# dsets.train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# dblock = DataBlock(get_items=get_image_files)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# dsets = dblock.datasets(path)\n",
    "# dsets.train[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# parent_label(fnames[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# data = ImageDataLoaders.from_folder(\n",
    "#     # path,\n",
    "#     # train='../input/ucfsubset/ucf-subset/train',\n",
    "#     # valid_pct=0.2,\n",
    "#     # ds_tfms=get_transforms(),\n",
    "#     # size=224,\n",
    "#     # num_workers=4).normalize(imagenet_stats)\n",
    "\n",
    "# data.classes\n",
    "\n",
    "#Out: ['A', 'B', 'C']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# with open('readme.txt', 'w') as f:\n",
    "#     f.write('Create a new text file!')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# # !pip install wget\n",
    "# !wget https://www.fillmurray.com/g/200/300"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# import wget"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# fname = wget.download('https://www.fillmurray.com/g/200/300')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# open(fname)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# # from PIL import Image\n",
    "# # from scipy.misc.pilutil import Image\n",
    "# # import imagio\n",
    "# import matplotlib.pyplot as plt\n",
    "# img = plt.imread(\"300\")\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# img.shape\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "[Tutorial Link](https://www.analyticsvidhya.com/blog/2019/09/step-by-step-deep-learning-tutorial-video-classification-python/)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# !git clone https://github.com/AlinaWithAFace/epilepsy-extension"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "# import cv2     # for capturing videos\n",
    "# import math   # for mathematical operations\n",
    "# import matplotlib.pyplot as plt    # for plotting the images\n",
    "# %matplotlib inline\n",
    "# import pandas as pd\n",
    "# from keras.preprocessing import image   # for preprocessing the images\n",
    "# import numpy as np    # for mathematical operations\n",
    "# from keras.utils import np_utils\n",
    "# from skimage.transform import resize   # for resizing images\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from glob import glob\n",
    "# from tqdm import tqdm\n",
    "# !pip install opencv-python"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "# # open the .txt file which have names of training videos\n",
    "# train_list_dir = \"../input/ucf101/UCF101TrainTestSplits-RecognitionTask/ucfTrainTestlist/trainlist01.txt\"\n",
    "# # train_list_dir = \"../data/ucfTrainTestlist/trainlist01.txt\"\n",
    "# f = open(train_list_dir, \"r\")\n",
    "# temp = f.read()\n",
    "# videos = temp.split('\\n')\n",
    "\n",
    "# # creating a dataframe having video names\n",
    "# train = pd.DataFrame()\n",
    "# train['video_name'] = videos\n",
    "# train = train[:-1]\n",
    "# train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# !pip install moviepy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "# import imageio\n",
    "# vid = imageio.get_reader(\"../input/potential-photosensitive-epilepy-flashing-videos/src_generator_samples_1-blue-black-9.avi\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# # means = []\n",
    "# for i,image in enumerate(vid.iter_data()):\n",
    "#     np.save(\"PatSavesTheDay.npy\", image)\n",
    "#     break\n",
    "#     #     means.append(image.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# np.load(\"PatSavesTheDay.npy\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# (0,1) (0, 255)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# plt.plot(np.diff(means))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# plt.plot(np.diff(means))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "# def rolling_window(a, window):\n",
    "#     shape = a.shape[:-1] + (a.shape[-1] - window + 1, window)\n",
    "#     strides = a.strides + (a.strides[-1],)\n",
    "#     return np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# plt.plot(np.var(rolling_window(np.array(means), 29), axis =1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "# plt.plot(np.var(rolling_window(np.array(means), 30), axis =1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "# np.var(np.diff(means))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# cap = cv2.VideoCapture('../input/ucf101/UCF101/UCF-101/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi')\n",
    "# frameCount = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# frameWidth = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "# frameHeight = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "# buf = np.empty((frameCount, frameHeight, frameWidth, 3), np.dtype('uint8'))\n",
    "\n",
    "# fc = 0\n",
    "# ret = True\n",
    "\n",
    "# while (fc < frameCount  and ret):\n",
    "#     ret, buf[fc] = cap.read()\n",
    "#     fc += 1\n",
    "\n",
    "# # cap.release()\n",
    "\n",
    "# # cv2.namedWindow('frame 10')\n",
    "# # cv2.imshow('frame 10', buf[9])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# cap.read()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# # open the .txt file which have names of test videos\n",
    "# test_list_dir = \"../input/ucf101/UCF101TrainTestSplits-RecognitionTask/ucfTrainTestlist/testlist01.txt\"\n",
    "# # test_list_dir = \"../data/ucfTrainTestlist/testlist01.txt\"\n",
    "# f = open(test_list_dir, \"r\")\n",
    "# temp = f.read()\n",
    "# videos = temp.split('\\n')\n",
    "\n",
    "# # creating a dataframe having video names\n",
    "# test = pd.DataFrame()\n",
    "# test['video_name'] = videos\n",
    "# test = test[:-1]\n",
    "# test.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# # creating tags for training videos\n",
    "# train_video_tag = []\n",
    "# for i in range(train.shape[0]):\n",
    "#     train_video_tag.append(train['video_name'][i].split('/')[0])\n",
    "\n",
    "# train['tag'] = train_video_tag\n",
    "\n",
    "# # creating tags for test videos\n",
    "# test_video_tag = []\n",
    "# for i in range(test.shape[0]):\n",
    "#     test_video_tag.append(test['video_name'][i].split('/')[0])\n",
    "\n",
    "# test['tag'] = test_video_tag\n",
    "\n",
    "# # print(test['tag'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# #from ipymol.compat import Image\n",
    "\n",
    "# from PIL import Image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # storing the frames from training videos\n",
    "# # for i in tqdm(range(train.shape[0])):\n",
    "# for i in tqdm(range(1)):\n",
    "#     count = 0\n",
    "#     videoFile = train['video_name'][i]\n",
    "#     video_root = '../input/ucf101/UCF101/UCF-101/'\n",
    "# #     video_root = \"../data/UCF-101/\"\n",
    "#     video_tag = train_video_tag[i]\n",
    "#     video_path = video_root + video_tag + \"/\"+ videoFile.split(' ')[0].split('/')[1]\n",
    "# #    eg path ../input/ucf101/UCF101/UCF-101/ApplyEyeMakeup/v_ApplyEyeMakeup_g08_c01.avi\n",
    "# #     print(video_path)\n",
    "#     cap = cv2.VideoCapture(video_path)   # capturing the video from the given path\n",
    "#     frameRate = cap.get(5) #frame rate\n",
    "#     x=1\n",
    "#     while(cap.isOpened()):\n",
    "#         frameId = cap.get(1) #current frame number\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "#         plt.imshow(frame)\n",
    "#         plt.show()\n",
    "#         filename = \"ucf-frames/train_1/image.jpg\"\n",
    "#         cv2.imwrite(filename, frame)\n",
    "# #         if (frameId % math.floor(frameRate) == 0):\n",
    "# #             # storing the frames in a new folder named train_1\n",
    "# # #             filename = \"train_1/\" + videoFile.split('/')[1].split(' ')[0] +\"_frame%d.jpg\" % count\n",
    "# # #             count+=1\n",
    "\n",
    "# #             print(filename)\n",
    "# #             cv2.imwrite(filename, frame)\n",
    "#     cap.release()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# # getting the names of all the images\n",
    "# images = glob(\"train_1/*.jpg\")\n",
    "# train_image = []\n",
    "# train_class = []\n",
    "# for i in tqdm(range(len(images))):\n",
    "#     # creating the image name\n",
    "#     train_image.append(images[i].split('/')[1])\n",
    "#     # creating the class of image\n",
    "#     train_class.append(images[i].split('/')[1].split('_')[1])\n",
    "\n",
    "# # storing the images and their class in a dataframe\n",
    "# train_data = pd.DataFrame()\n",
    "# train_data['image'] = train_image\n",
    "# train_data['class'] = train_class\n",
    "\n",
    "# # converting the dataframe into csv file\n",
    "# train_data.to_csv('UCF/train_new.csv',header=True, index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.models import Sequential\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "# from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "# from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "# from keras.preprocessing import image\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "# from sklearn.model_selection import train_test_split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "# train = pd.read_csv('UCF/train_new.csv')\n",
    "# train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "# # creating an empty list\n",
    "# train_image = []\n",
    "\n",
    "# # for loop to read and store frames\n",
    "# for i in tqdm(range(train.shape[0])):\n",
    "#     # loading the image and keeping the target size as (224,224,3)\n",
    "#     img = image.load_img('train_1/'+train['image'][i], target_size=(224,224,3))\n",
    "#     # converting it to array\n",
    "#     img = image.img_to_array(img)\n",
    "#     # normalizing the pixel value\n",
    "#     img = img/255\n",
    "#     # appending the image to the train_image list\n",
    "#     train_image.append(img)\n",
    "\n",
    "# # converting the list to numpy array\n",
    "# X = np.array(train_image)\n",
    "\n",
    "# # shape of the array\n",
    "# X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "# # separating the target\n",
    "# y = train['class']\n",
    "\n",
    "# # creating the training and validation set\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify = y)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}